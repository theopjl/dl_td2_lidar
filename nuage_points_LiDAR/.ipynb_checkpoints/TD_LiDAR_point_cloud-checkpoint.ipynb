{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "721e61c4",
   "metadata": {},
   "source": [
    "### Lab session: representing a digital surface model with a neural network"
   ]
  },
  {
   "cell_type": "code",
   "id": "8ee80419",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "pipeline = \"\"\"\n",
    "[\n",
    "    \"LHD_FXX_0808_6485_PTS_C_LAMB93_IGN69.copc.laz\",\n",
    "    {\n",
    "        \"type\": \"filters.sort\",\n",
    "        \"dimension\": \"Z\"\n",
    "    }\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "import pdal\n",
    "r = pdal.Pipeline(pipeline)\n",
    "#r.validate()\n",
    "r.execute()\n",
    "arrays = r.arrays\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d6181731",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "N = arrays[0].shape[0]\n",
    "X = np.zeros(N,)\n",
    "Y = np.zeros(N,)\n",
    "Z = np.zeros(N,)\n",
    "I = np.zeros(N,)\n",
    "\n",
    "for n in range(N):\n",
    "    pt = arrays[0][n]\n",
    "    X[n] = pt[0]\n",
    "    Y[n] = pt[1]\n",
    "    Z[n] = pt[2]\n",
    "    I[n] = pt[3]\n",
    "\n",
    "print(len(X[::100]))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4e4cf6e8",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(1)\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(X[::100], Y[::100], Z[::100], c=Z[::100], marker='o', s=1)\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "91611ab9",
   "metadata": {},
   "source": [
    "selx = (X>808305)*(X<808538)\n",
    "sely = (Y>6484516)*(Y<6484626)\n",
    "sel = selx*sely\n",
    "\n",
    "I[I>10000] = 10000 #np.max(I[I!=np.max(I)])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "04d5125c",
   "metadata": {},
   "source": [
    "fig = plt.figure(2)\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(X[sel], Y[sel], Z[sel], c=I[sel], marker='o', s=1, cmap='gray')\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2fa26921",
   "metadata": {},
   "source": [
    "Xsel = X[sel]\n",
    "Ysel = Y[sel]\n",
    "Zsel = Z[sel]\n",
    "Isel = I[sel]\n",
    "Nsel = Xsel.shape[0]\n",
    "\n",
    "Nsmall = 50000\n",
    "pts = np.rint(np.linspace(Nsel/(2*(Nsmall-1)),Nsel-Nsel/(2*(Nsmall-1)),num=Nsmall)+(np.random.rand(Nsmall)-.5)*Nsel/(Nsmall-1)).astype(np.int32)-1\n",
    "\n",
    "Xsmall = Xsel[pts]\n",
    "Ysmall = Ysel[pts]\n",
    "Zsmall = Zsel[pts]\n",
    "Ismall = Isel[pts]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6b0a305b",
   "metadata": {},
   "source": [
    "Ismall[Ismall==np.max(Ismall)] = np.max(Ismall[Ismall!=np.max(Ismall)])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "834fd3cc",
   "metadata": {},
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "# ax.scatter(Xsmall, Ysmall, Zsmall, c=Ismall.astype(np.float64), marker='o', s=1)\n",
    "# ax.scatter(Xsmall, Ysmall, Zsmall, c=(Ismall.astype(np.float64)-np.min(Ismall))/(np.max(Ismall)-np.min(Ismall)), marker='o', s=1,cmap='gray')\n",
    "ax.scatter(Xsmall, Ysmall, Zsmall, c=(Ismall.astype(np.float64))/np.max(Ismall), marker='o', s=1,cmap='gray')\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ad2eaf9b",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
    "\n",
    "# F(x, y) = z\n",
    "\n",
    "# STACKING INPUTS IN (N,2) MATRIX\n",
    "inputs = np.stack([Xsmall, Ysmall], axis=1)\n",
    "\n",
    "# SHAPING OUTPUT IN (N, 1)\n",
    "targets = Zsmall.reshape(-1, 1)\n",
    "# CONVERTING NUMPY ARRAYS TO TENSOR\n",
    "i_tensor = torch.tensor(inputs, dtype=torch.float32)\n",
    "o_tensor = torch.tensor(targets, dtype=torch.float32)\n",
    "\n",
    "# COMPLETE DATASET\n",
    "dataset = TensorDataset(i_tensor, o_tensor)\n",
    "\n",
    "# SPLITTING IN DIFFERENT SIZES\n",
    "N = len(dataset)\n",
    "n_train = int(0.7*N)\n",
    "n_val = int(0.15*N)\n",
    "n_test = int(0.15*N)\n",
    "\n",
    "# RANDOM ATTRIBUTION\n",
    "train_set, val_set, test_set = random_split(dataset, [n_train, n_val, n_test], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "print(f\"Train : {len(train_set)}, Val : {len(val_set)}, Test : {len(test_set)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ad5d7084",
   "metadata": {},
   "source": [
    "from torch import nn\n",
    "\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\" \n",
    "\n",
    "class NeuralNetwork(nn.Module) :\n",
    "    def __init__(self, input_dim, output_dim, width, depth = 3, activation = 'relu') :\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        self.factivation = nn.ReLU() if (isinstance(activation, str) and activation == 'relu') else nn.Sigmoid()\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        # INPUT LAYER\n",
    "        layers.append(nn.Linear(input_dim, width))\n",
    "        layers.append(self.factivation)\n",
    "\n",
    "        # HIDDEN LAYERS\n",
    "        for _ in range(depth - 1) :\n",
    "            layers.append(nn.Linear(width, width))\n",
    "            layers.append(self.factivation)\n",
    "\n",
    "        # OUTPUT LAYER\n",
    "        layers.append(nn.Linear(width, output_dim))\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x) :\n",
    "        return self.net(x)\n",
    "\n",
    "class CustomOptimizer():\n",
    "    def __init__(self, params, lr) :\n",
    "        self.params = list(params)\n",
    "        super().__init__()\n",
    "\n",
    "    def sgd(self) :\n",
    "        for p in self.params :\n",
    "            if p.grad is not None :\n",
    "                p = torch.sub(p, self.lr * p.grad)\n",
    "                # p.data -= learning_rate * p.grad.data\n",
    "                p.grad.data.zero_()\n",
    "\n",
    "    def zeroing_grad(self) :\n",
    "        for p in self.params :\n",
    "            if p.grad is not None :\n",
    "                p.grad.data.zero_()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# HYPER PARAMETERS\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "# LOSS FUNCTION\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# MODEL INITIALIZATION\n",
    "model = NeuralNetwork(2, 1, 64, 3, 'relu').to(device)\n",
    "print(model)\n",
    "\n",
    "# OUR CUSTOM OPTIMIZER FOR SGD\n",
    "coptimizer = CustomOptimizer(model.parameters(), learning_rate)"
   ],
   "id": "78e24b4b9d305f59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load datas",
   "id": "a5d5008c10fbd325"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# DATALOADERS\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=True)"
   ],
   "id": "c11d58088ed5215f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6524931e",
   "metadata": {},
   "source": [
    "def train(model, loss_fn, optimizer) :\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    # TRAINING LOOP\n",
    "    for epoch in range(epochs) :\n",
    "        for xi, yi in train_loader :\n",
    "            pred = model(xi)\n",
    "            loss = loss_fn(pred, yi)\n",
    "\n",
    "            coptimizer.zeroing_grad()\n",
    "            loss.backward()\n",
    "            coptimizer.sgd()\n",
    "\n",
    "            total_loss += loss.item() * len(xi)\n",
    "\n",
    "        train_loss = total_loss / len(train_set)\n",
    "\n",
    "        # VALIDATING LOOP\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "\n",
    "        with torch.no_grad() :\n",
    "            for xi, yi in val_loader :\n",
    "                pred = model(xi)\n",
    "                loss = loss_fn(pred, yi)\n",
    "                total_val_loss += loss.item() * len(xi)\n",
    "        val_loss = total_val_loss / len(val_set)\n",
    "\n",
    "        print(f\"Epoch {epoch+1:02d}/{epochs} | Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f}\")\n",
    "    print(\"\\n---Done training---\")\n",
    "\n",
    "def test(model, loss_fn) :\n",
    "    model.eval()\n",
    "    total_test_loss, correct = 0\n",
    "\n",
    "    # don't trace gradient here to avoid duplicates and gain precious computational ressources.\n",
    "    # No need to compute sgd here, we only want to evaluate the predictions\n",
    "    with torch.no_grad() :\n",
    "        for xi, yi in test_loader :\n",
    "            pred = model(xi)\n",
    "            loss = loss_fn(pred, yi)\n",
    "            total_test_loss += loss.item() * len(xi)\n",
    "            correct += (pred.argmax(1) == yi).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss = total_test_loss / len(test_set)\n",
    "    correct /= len(test_set)\n",
    "\n",
    "    print(f\"Test Loss: {test_loss:.6f}\")\n",
    "    print(f\"Correct: {correct}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train(model, loss_fn, coptimizer)\n",
    "test(model, loss_fn)"
   ],
   "id": "918c32f8858036ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "285a8cd9f93ef10b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
